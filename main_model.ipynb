{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrWXErSxVlqz"
      },
      "source": [
        "# **Collaborative Flitering**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JybUGwoOWiGW"
      },
      "source": [
        "Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zWRW9ASvVS5Q"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVmuxIbx69OJ"
      },
      "source": [
        "# **Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/kucingku-capstone/machine-learning/main/dataset/clean_cats_dataset.csv')\n"
      ],
      "metadata": {
        "id": "vAjNd0cgcR-I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "LjmpcOJ2f2ds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Data preprocessing\n",
        "user_encoder = LabelEncoder()\n",
        "cat_encoder = LabelEncoder()\n",
        "\n",
        "df['user_id'] = user_encoder.fit_transform(df['user_id'].astype(str))\n",
        "df['cat_id'] = cat_encoder.fit_transform(df['cat_id'].astype(str))\n"
      ],
      "metadata": {
        "id": "C-0D1qNZc0Cq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split Dataset into Training and Testing Sets**"
      ],
      "metadata": {
        "id": "Zvohe6GCf3CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Split the dataset into training and testing sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "RUU5_ehUc2Pc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Collaborative Filtering Model using TensorFlow**"
      ],
      "metadata": {
        "id": "gr9_oIvPf3xA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Create the collaborative filtering model using TensorFlow\n",
        "num_users = len(user_encoder.classes_)\n",
        "num_cats = len(cat_encoder.classes_)\n",
        "embedding_size = 50\n",
        "\n",
        "# User embedding layer\n",
        "user_input = Input(shape=(1,), name='user_input')\n",
        "user_embedding = Embedding(input_dim=num_users, output_dim=embedding_size, input_length=1)(user_input)\n",
        "user_embedding = Flatten()(user_embedding)\n",
        "\n",
        "# Cat embedding layer\n",
        "cat_input = Input(shape=(1,), name='cat_input')\n",
        "cat_embedding = Embedding(input_dim=num_cats, output_dim=embedding_size, input_length=1)(cat_input)\n",
        "cat_embedding = Flatten()(cat_embedding)\n",
        "\n",
        "# Concatenate user and cat embeddings\n",
        "concatenated = Concatenate()([user_embedding, cat_embedding])\n",
        "\n",
        "# Add additional dense layers\n",
        "dense_layer_1 = Dense(128, activation='relu')(concatenated)\n",
        "dense_layer_2 = Dense(64, activation='relu')(dense_layer_1)\n",
        "\n",
        "# Dot product of user and cat embeddings\n",
        "dot_product = Dense(1, activation='linear')(dense_layer_2)\n",
        "\n",
        "# Combine all layers into a model\n",
        "model = Model(inputs=[user_input, cat_input], outputs=dot_product)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n"
      ],
      "metadata": {
        "id": "SIS-nQfnc-Y-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model"
      ],
      "metadata": {
        "id": "Isv0adHqf4zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    x=[train_df['user_id'], train_df['cat_id']],\n",
        "    y=train_df['rating'],\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7QXiDHOdBbG",
        "outputId": "bf616729-f917-4bee-9910-787b99d1e0fd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "347/347 [==============================] - 18s 50ms/step - loss: 1.9029 - val_loss: 0.8784\n",
            "Epoch 2/15\n",
            "347/347 [==============================] - 16s 47ms/step - loss: 0.4810 - val_loss: 0.9704\n",
            "Epoch 3/15\n",
            "347/347 [==============================] - 17s 49ms/step - loss: 0.2177 - val_loss: 0.9718\n",
            "Epoch 4/15\n",
            "347/347 [==============================] - 17s 49ms/step - loss: 0.0639 - val_loss: 0.9460\n",
            "Epoch 5/15\n",
            "347/347 [==============================] - 15s 44ms/step - loss: 0.0527 - val_loss: 0.9408\n",
            "Epoch 6/15\n",
            "347/347 [==============================] - 17s 50ms/step - loss: 0.0397 - val_loss: 0.9488\n",
            "Epoch 7/15\n",
            "347/347 [==============================] - 17s 48ms/step - loss: 0.0380 - val_loss: 0.9417\n",
            "Epoch 8/15\n",
            "347/347 [==============================] - 18s 51ms/step - loss: 0.0374 - val_loss: 0.9330\n",
            "Epoch 9/15\n",
            "347/347 [==============================] - 17s 48ms/step - loss: 0.0322 - val_loss: 0.9259\n",
            "Epoch 10/15\n",
            "347/347 [==============================] - 16s 47ms/step - loss: 0.0315 - val_loss: 0.9254\n",
            "Epoch 11/15\n",
            "347/347 [==============================] - 17s 48ms/step - loss: 0.0278 - val_loss: 0.9165\n",
            "Epoch 12/15\n",
            "347/347 [==============================] - 17s 49ms/step - loss: 0.0266 - val_loss: 0.9054\n",
            "Epoch 13/15\n",
            "347/347 [==============================] - 19s 55ms/step - loss: 0.0259 - val_loss: 0.9166\n",
            "Epoch 14/15\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 0.0246 - val_loss: 0.9086\n",
            "Epoch 15/15\n",
            "347/347 [==============================] - 16s 47ms/step - loss: 0.0237 - val_loss: 0.9119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate the Model on the Test Set**"
      ],
      "metadata": {
        "id": "ku_cd2-hf5qM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Evaluate the model on the test set\n",
        "test_loss = model.evaluate(x=[test_df['user_id'], test_df['cat_id']], y=test_df['rating'])\n",
        "print(f'Test Loss: {test_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "camTf-gNdCLk",
        "outputId": "fa65ec42-4846-4f9c-fb63-8d73b6a0e69b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "217/217 [==============================] - 1s 3ms/step - loss: 0.9238\n",
            "Test Loss: 0.923750102519989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Make Predictions**"
      ],
      "metadata": {
        "id": "tZf0Qrw9f6In"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rest of the code for making predictions...\n",
        "# Step 6: Make predictions for a specific user\n",
        "user_index_example = 0\n",
        "user_input_example = np.array([user_index_example])\n",
        "\n",
        "# Provide a single cat index for each prediction\n",
        "cat_indices = np.arange(num_cats)\n",
        "\n",
        "# Reshape user input to have the same shape as cat_indices\n",
        "user_input_example = np.repeat(user_input_example, num_cats)\n",
        "\n",
        "predictions = model.predict([user_input_example, cat_indices])\n",
        "\n",
        "# Get top recommendations\n",
        "top_cat_indices = np.argsort(predictions.flatten())[::-1][:5]\n",
        "top_cat_ids = cat_encoder.inverse_transform(top_cat_indices)\n",
        "\n",
        "print(top_cat_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy_apT61dJqe",
        "outputId": "70168e91-0dfa-452c-96e9-6f65943167eb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1084/1084 [==============================] - 2s 1ms/step\n",
            "['46118240' '31958270' '34313667' '46209900' '40550873']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save Model To H5**"
      ],
      "metadata": {
        "id": "5m9MqxASf6xN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model to h5\n",
        "model.save(\"collaborative_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGS4MCWwerWB",
        "outputId": "1b1d24a7-c0f9-448e-e300-ee337d5b11ee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loss Test from model**"
      ],
      "metadata": {
        "id": "n1pV9hxgf7ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from the h5 file\n",
        "loaded_model = tf.keras.models.load_model(\"collaborative_model.h5\")\n",
        "\n",
        "# Evaluate the loaded model on the test set\n",
        "test_loss = loaded_model.evaluate(x=[test_df['user_id'], test_df['cat_id']], y=test_df['rating'])\n",
        "print(f'Test Loss: {test_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHPy1U_Zewp9",
        "outputId": "ccf4fb23-4fe5-4c2b-8981-e388e74f8460"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "217/217 [==============================] - 1s 2ms/step - loss: 0.9238\n",
            "Test Loss: 0.923750102519989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convert to TFLITE**"
      ],
      "metadata": {
        "id": "I9FUZzAnf9I-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the Keras model\n",
        "loaded_model = tf.keras.models.load_model(\"collaborative_model.h5\")\n",
        "\n",
        "# Convert the Keras model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TensorFlow Lite model to a file\n",
        "with open(\"collaborative_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n"
      ],
      "metadata": {
        "id": "5lQQpdPGe-Za"
      },
      "execution_count": 17,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}